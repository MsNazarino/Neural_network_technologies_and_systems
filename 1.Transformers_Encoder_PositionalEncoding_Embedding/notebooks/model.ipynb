{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7a46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4344d086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21ee0f",
   "metadata": {},
   "source": [
    "### `–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e70132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!\n",
      "–†–æ–∑–º—ñ—Ä –¥–∞—Ç–∞—Å–µ—Ç—É: (5572, 2)\n",
      "      label                                            message\n",
      "1011      0        I just got home babe, are you still awake ?\n",
      "4833      0                      I hope your pee burns tonite.\n",
      "4577      1  Urgent! call 09066350750 from your landline. Y...\n",
      "2570      0                   From 5 to 2 only my work timing.\n",
      "2354      0               R we going with the  &lt;#&gt;  bus?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/spam.csv\", encoding='latin-1')\n",
    "\n",
    "data = data[['v1', 'v2']]\n",
    "data.columns = ['label', 'message']\n",
    "\n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "print(\"–§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!\")\n",
    "print(\"–†–æ–∑–º—ñ—Ä –¥–∞—Ç–∞—Å–µ—Ç—É:\", data.shape)\n",
    "print(data.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813f673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–ª–∞—Å 0 –º–∞—î 4825 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤\n",
      "–ö–ª–∞—Å 1 –º–∞—î 747 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤\n"
     ]
    }
   ],
   "source": [
    "for a in data['label'].unique():\n",
    "    print(f\"–ö–ª–∞—Å {a} –º–∞—î {data[data['label'] == a].shape[0]} –ø—Ä–∏–∫–ª–∞–¥—ñ–≤\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ada95",
   "metadata": {},
   "source": [
    "### `–¢–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e40fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_data(texts, tokenizer, max_len=64):\n",
    "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e35e5",
   "metadata": {},
   "source": [
    "### `–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç—É —Ç–∞ –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è –∫–ª–∞—Å—ñ–≤`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32df6cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–æ –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è:\n",
      "ham: 4825 | spam: 747\n",
      "\n",
      "–ü—ñ—Å–ª—è –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è:\n",
      "label\n",
      "0    4825\n",
      "1    4825\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "majority = data[data['label'] == 0]  # ham\n",
    "minority = data[data['label'] == 1]  # spam\n",
    "\n",
    "print(\"–î–æ –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è:\")\n",
    "print(\"ham:\", len(majority), \"| spam:\", len(minority))\n",
    "\n",
    "# Oversampling –º–µ–Ω—à–æ–≥–æ –∫–ª–∞—Å—É (spam)\n",
    "minority_upsampled = resample(\n",
    "    minority,\n",
    "    replace=True,                # –∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–Ω—è–º\n",
    "    n_samples=len(majority),     # –¥–æ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ ham\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "balanced_data = pd.concat([majority, minority_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "balanced_data.to_csv('../data/balanced_data.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"\\n–ü—ñ—Å–ª—è –±–∞–ª–∞–Ω—Å—É–≤–∞–Ω–Ω—è:\")\n",
    "print(balanced_data['label'].value_counts())\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    balanced_data['message'], balanced_data['label'], test_size=0.2, random_state=42, stratify=balanced_data['label']\n",
    ")\n",
    "\n",
    "train_encodings = tokenize_data(train_texts, tokenizer)\n",
    "test_encodings = tokenize_data(test_texts, tokenizer)\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SpamDataset(train_encodings, train_labels)\n",
    "test_dataset = SpamDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d45ef5",
   "metadata": {},
   "source": [
    "### `–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª—ñ`\n",
    "#### `PositionalEncoding, Embedding, TransformerEncoderLayer(2 —à–∞—Ä–∏), Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9474016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–∑–∏—Ü—ñ–π–Ω–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n",
    "\n",
    "class SimpleTransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers=2, num_classes=2, dim_feedforward=256):\n",
    "\n",
    "        super(SimpleTransformerClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            batch_first=False  # permute(1,0,2)\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        x = self.embedding(input_ids)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.permute(1, 0, 2)  # (seq_len, batch, d_model)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=0)       \n",
    "        out = self.fc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785d372",
   "metadata": {},
   "source": [
    "### `–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ —Ç–∞ —Ç—é–Ω—ñ–Ω–≥ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ d_model=128, nhead=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gnatu\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/3, avg loss = 0.3016\n",
      "  Epoch 2/3, avg loss = 0.1069\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "d_models = [128, 256, 512]  \n",
    "nheads = [2, 4, 8]           \n",
    "num_epochs = 3\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "for d_m, nh in product(d_models, nheads):\n",
    "    print(f\"\\n-> –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ d_model={d_m}, nhead={nh}\")\n",
    "    model = SimpleTransformerClassifier(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        d_model=d_m,\n",
    "        nhead=nh,\n",
    "        num_layers=2\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"  Epoch {epoch+1}/{num_epochs}, avg loss = {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a695e07",
   "metadata": {},
   "source": [
    "### `–û—Ü—ñ–Ω–∫–∞ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6645065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üîπ Acc: 0.99689 | Prec: 0.99382 | Rec: 1.00000 | F1: 0.99690\n",
      "  ‚úÖ –ù–æ–≤—ñ –Ω–∞–π–∫—Ä–∞—â—ñ –≤–∞–≥–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ!\n",
      "\n",
      "üèÜ –ù–∞–π–∫—Ä–∞—â–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è: d_model=512, nhead=8 –∑ F1=0.996901\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds, true_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids)\n",
    "        preds += torch.argmax(outputs, dim=1).cpu().tolist()\n",
    "        true_labels += labels.cpu().tolist()\n",
    "\n",
    "acc = accuracy_score(true_labels, preds)\n",
    "prec = precision_score(true_labels, preds)\n",
    "rec = recall_score(true_labels, preds)\n",
    "f1 = f1_score(true_labels, preds)\n",
    "\n",
    "print(f\"  üîπ Acc: {acc:.5f} | Prec: {prec:.5f} | Rec: {rec:.5f} | F1: {f1:.5f}\")\n",
    "\n",
    "if f1 > best_f1:\n",
    "    best_f1 = f1\n",
    "    best_params = (d_m, nh)\n",
    "    torch.save(model.state_dict(), \"best_simple_transformer.pt\")\n",
    "    print(\"  ‚úÖ –ù–æ–≤—ñ –Ω–∞–π–∫—Ä–∞—â—ñ –≤–∞–≥–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ!\")\n",
    "\n",
    "# —Ü–µ–π print —É–∂–µ –ø—ñ—Å–ª—è –≤—Å—ñ—Ö –ø–µ—Ä–µ–≤—ñ—Ä–æ–∫\n",
    "print(f\"\\nüèÜ –ù–∞–π–∫—Ä–∞—â–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è: d_model={best_params[0]}, nhead={best_params[1]} –∑ F1={best_f1:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05c0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
